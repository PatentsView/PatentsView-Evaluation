{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Results\n",
    "Before verification using cluster precision/recall analysis, the output requires cleaning. The goal of obtaining sequence numbers was to have a unique identifier for patent-inventor instances. However, the our results contain 42 duplicate indices which is clearly an issue. Thus, manual review was used to fix these incorrect sequence numbers. Additionally, we can resolve the 163 cases where **get_sequence()** reported 'No Match'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Imports\n",
    "Loading in the results from **get-inventor-sequence-number**. We then split up the dataframe into 'autosequence' (completed cases), 'no_sequence' (sequence number is \"NaN\"), and 'duplicated' (duplicate mention_id)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Initial autosequence length': 142619, 'Separated autosequence length': 142363, 'No sequence length': 214, 'Duplicated length': 42}\n"
     ]
    }
   ],
   "source": [
    "#read in results\n",
    "autosequence = pd.read_csv('output/autosequence.csv', index_col = 0, dtype=\"string\")\n",
    "init_length = len(autosequence)\n",
    "\n",
    "#separate dataframe into one with sequence numbers and one without\n",
    "no_sequence = autosequence[autosequence['sequence'].isna()]\n",
    "autosequence = autosequence[autosequence['sequence'].isna() == False]\n",
    "\n",
    "#get mention id\n",
    "autosequence['mention'] = \"US\" + autosequence.patent + \"-\" + autosequence.sequence\n",
    "\n",
    "#separate dataframe (with sequence numbers) into one with duplicates and one wihtout\n",
    "duplicated = autosequence[autosequence.mention.duplicated(keep=False)]\n",
    "autosequence = autosequence[autosequence.mention.duplicated(keep=False) == False]\n",
    "\n",
    "print({\"Initial autosequence length\": init_length, \"Separated autosequence length\": len(autosequence), \n",
    "    \"No sequence length\": len(no_sequence), \"Duplicated length\": len(duplicated)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are again loading in **rawinventor.tsv** to use in our manual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in raw_inventor (and sorting for efficiency)\n",
    "rawinventor = pd.read_csv(\"input/rawinventor.tsv\", sep=\"\\t\", usecols=[\"patent_id\", \"sequence\", \"name_first\", \"name_last\"], \n",
    "    dtype={\"patent_id\": \"string\", \"sequence\": \"int16\", \"name_first\": \"string\", \"name_last\": \"string\"})\n",
    "rawinventor.set_index(['patent_id', 'sequence'], inplace=True)\n",
    "rawinventor.sort_index(inplace=True)\n",
    "rawinventor.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Inspection\n",
    "Below are two separate processes for manual inspection: one of no_sequence cases and the other of duplicated cases. Results are stored in the variables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables for storing manual results\n",
    "no_sequence_results = []\n",
    "no_sequence_observed = set()\n",
    "duplicated_results = []\n",
    "duplicated_observed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually entering sequence number for no_sequence cases\n",
    "for index, dict in no_sequence.iterrows():\n",
    "    if index not in no_sequence_observed:\n",
    "        if dict.patent in rawinventor.index:\n",
    "            print(pd.DataFrame(dict).T)\n",
    "            print(rawinventor.loc[dict.patent])\n",
    "            dict.sequence = input(\"Sequence number: \")\n",
    "            no_sequence_observed.add(index)\n",
    "            no_sequence_results.append(dict)\n",
    "            clear_output(wait = True)\n",
    "        else:\n",
    "            dict.sequence = \"NaN\"\n",
    "            no_sequence_observed.add(index)\n",
    "            no_sequence_results.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manually entering sequence number for duplicated cases\n",
    "for patent, dict in duplicated.groupby('patent'):\n",
    "    if patent not in duplicated_observed:\n",
    "        if patent in rawinventor.index:\n",
    "            print(dict)\n",
    "            print(rawinventor.loc[patent])\n",
    "            dict.sequence[0] = input(\"First sequence number: \")\n",
    "            dict.sequence[1] = input(\"Second sequence number: \")\n",
    "            duplicated_observed.add(patent)\n",
    "            duplicated_results.append(dict)\n",
    "            clear_output(wait = True)\n",
    "        else: #shouldn't encounter but just in case\n",
    "            print(\"error\")\n",
    "            input(\"move on?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "The final step is to combine our three dataframes after 'no_sequence' and 'duplicated' are resolved of errors. After concatenation, we write our **autosequence_cleaned.csv** file and a separate **autosequence_errors.csv** file for cases which could not be resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting our results to pandas dataframes\n",
    "no_sequence = pd.DataFrame(no_sequence_results, dtype=\"string\")\n",
    "duplicated_results = [dict for i in range(len(duplicated_results)) for index, dict in duplicated_results[i].iterrows()] #flatten\n",
    "duplicated = pd.DataFrame(duplicated_results, dtype=\"string\")\n",
    "\n",
    "#separating\n",
    "no_sequence_errors = no_sequence[no_sequence['sequence'] == \"NaN\"]\n",
    "no_sequence = no_sequence[no_sequence['sequence'] != \"NaN\"]\n",
    "duplicated_errors = duplicated[duplicated['sequence'] == \"NaN\"].drop('mention', axis='columns')\n",
    "duplicated = duplicated[duplicated['sequence'] != \"NaN\"]\n",
    "\n",
    "#updating identifier\n",
    "no_sequence['mention'] = \"US\" + no_sequence.patent + \"-\" + no_sequence.sequence\n",
    "duplicated['mention'] = \"US\" + duplicated.patent + \"-\" + duplicated.sequence\n",
    "\n",
    "#combining final output\n",
    "autosequence_cleaned = pd.concat([autosequence, no_sequence, duplicated])\n",
    "autosequence_cleaned.set_index('mention', inplace = True)\n",
    "autosequence_errors = pd.concat([no_sequence_errors, duplicated_errors])\n",
    "\n",
    "if not os.path.isfile(\"output/autosequence_cleaned.csv\"):\n",
    "    autosequence_cleaned.to_csv('output/autosequence_cleaned.csv')\n",
    "    autosequence_errors.to_csv('output/autosequence_errors.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
