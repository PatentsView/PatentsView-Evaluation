
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>pv_evaluation.benchmark &#8212; PatentsView-Evaluation  documentation</title>
<script>
  document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
  document.documentElement.dataset.theme = localStorage.getItem("theme") || "light"
</script>

  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=92025949c220c2e29695" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=92025949c220c2e29695" rel="stylesheet">


  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx_lesson.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />

  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/minipres.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="pv_evaluation.templates" href="pv_evaluation.templates.html" />
    <link rel="prev" title="pv_evaluation.metrics" href="pv_evaluation.metrics.html" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="docsearch:language" content="None">
  </head>
  
  
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="180" data-default-mode="">
    <div class="bd-header-announcement container-fluid" id="banner">
      

    </div>

    
    <nav class="bd-header navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="bd-header__inner container-xl">

  <div id="navbar-start">
    
    
  


<a class="navbar-brand logo" href="index.html">
  
  
  
  
  
    <p class="title logo__title">PatentsView-Evaluation  documentation</p>
  
</a>
    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="fas fa-bars"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="readme.html">
  README
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="concepts.html">
  Key Concepts
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="examples.html">
  Examples
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="pv_evaluation.html">
  API Doc
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <span id="theme-switch" class="btn btn-sm btn-outline-primary navbar-btn rounded-circle">
    <a class="theme-switch" data-mode="light"><i class="fas fa-sun"></i></a>
    <a class="theme-switch" data-mode="dark"><i class="far fa-moon"></i></a>
    <a class="theme-switch" data-mode="auto"><i class="fas fa-adjust"></i></a>
</span>
      </div>
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="bd-container container-xl">
      <div class="bd-container__inner row">
          

<!-- Only show if we have sidebars configured, else just a small margin  -->
<div class="bd-sidebar-primary col-12 col-md-3 bd-sidebar">
  <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="pv_evaluation.summary.html">
   pv_evaluation.summary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pv_evaluation.metrics.html">
   pv_evaluation.metrics
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   pv_evaluation.benchmark
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pv_evaluation.templates.html">
   pv_evaluation.templates
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pv_evaluation.estimators.html">
   pv_evaluation.estimators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="pv_evaluation.utils.html">
   pv_evaluation.utils
  </a>
 </li>
</ul>

  </div>
</nav>
  </div>
  <div class="sidebar-end-items">
  </div>
</div>


          


<div class="bd-sidebar-secondary d-none d-xl-block col-xl-2 bd-toc">
  
    
    <div class="toc-item">
      
<div class="tocsection onthispage mt-5 pt-1 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#contents">
   Contents
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#module-pv_evaluation.benchmark">
   Documentation
  </a>
 </li>
</ul>

</nav>
    </div>
    
    <div class="toc-item">
      
    </div>
    
  
</div>


          
          
          <div class="bd-content col-12 col-md-9 col-xl-7">
              
              <article class="bd-article" role="main">
                
  <section id="pv-evaluation-benchmark">
<h1>pv_evaluation.benchmark<a class="headerlink" href="#pv-evaluation-benchmark" title="Permalink to this headline">#</a></h1>
<section id="contents">
<h2>Contents<a class="headerlink" href="#contents" title="Permalink to this headline">#</a></h2>
<table class="autosummary longtable table autosummary">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.inspect_clusters_to_merge" title="pv_evaluation.benchmark.inspect_clusters_to_merge"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inspect_clusters_to_merge</span></code></a></p></td>
<td><p>Get table to inspect missing cluster links given a benchmark dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.inspect_clusters_to_split" title="pv_evaluation.benchmark.inspect_clusters_to_split"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inspect_clusters_to_split</span></code></a></p></td>
<td><p>Get table of cluster assignment errors on the given benchmark.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.inventor_benchmark_plot" title="pv_evaluation.benchmark.inventor_benchmark_plot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inventor_benchmark_plot</span></code></a></p></td>
<td><p>Bar plot of performance evaluation metrics on benchmark datasets.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.inventor_benchmark_table" title="pv_evaluation.benchmark.inventor_benchmark_table"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inventor_benchmark_table</span></code></a></p></td>
<td><p>Compute performance evaluation metrics on benchmark datasets.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.load_israeli_inventors_benchmark" title="pv_evaluation.benchmark.load_israeli_inventors_benchmark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_israeli_inventors_benchmark</span></code></a></p></td>
<td><p>Israeli inventors benchmark dataset</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.load_lai_2011_inventors_benchmark" title="pv_evaluation.benchmark.load_lai_2011_inventors_benchmark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_lai_2011_inventors_benchmark</span></code></a></p></td>
<td><p>Lai's 2011 inventors benchmark dataset</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.load_patentsview_inventors_benchmark" title="pv_evaluation.benchmark.load_patentsview_inventors_benchmark"><code class="xref py py-obj docutils literal notranslate"><span class="pre">load_patentsview_inventors_benchmark</span></code></a></p></td>
<td><p>PatentsView hand-disambiguated inventors benchmark</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#pv_evaluation.benchmark.style_cluster_inspection" title="pv_evaluation.benchmark.style_cluster_inspection"><code class="xref py py-obj docutils literal notranslate"><span class="pre">style_cluster_inspection</span></code></a></p></td>
<td><p>Style table to highlight groups with alternating colors.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="module-pv_evaluation.benchmark">
<span id="documentation"></span><h2>Documentation<a class="headerlink" href="#module-pv_evaluation.benchmark" title="Permalink to this headline">#</a></h2>
<p>Evaluation datasets and standardized benchmarks</p>
<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.inspect_clusters_to_merge">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">inspect_clusters_to_merge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">disambiguation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">join_with</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.inspect_clusters_to_merge" title="Permalink to this definition">#</a></dt>
<dd><p>Get table to inspect missing cluster links given a benchmark dataset.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>disambiguation</strong> (<em>Series</em>) – disambiguation result Series (disambiguation results are pandas Series with “mention-id” index and cluster assignment values).</p></li>
<li><p><strong>benchmark</strong> (<em>Series</em>) – reference disambiguation Series.</p></li>
<li><p><strong>join_with</strong> (<em>DataFrame</em><em>, </em><em>optional</em>) – DataFrame to join based on “mention-id”. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DataFrame containing missing cluster links according to the given benchmark.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.inspect_clusters_to_split">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">inspect_clusters_to_split</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">disambiguation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmark</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">join_with</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.inspect_clusters_to_split" title="Permalink to this definition">#</a></dt>
<dd><p>Get table of cluster assignment errors on the given benchmark.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>disambiguation</strong> (<em>Series</em>) – disambiguation result Series (disambiguation results are pandas Series with “mention-id” index and cluster assignment values).</p></li>
<li><p><strong>benchmark</strong> (<em>Series</em>) – reference disambiguation Series.</p></li>
<li><p><strong>join_with</strong> (<em>DataFrame</em><em>, </em><em>optional</em>) – DataFrame to join based on “mention-id”. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>DataFrame containing erroneous cluster assignments according to the given benchmark.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>DataFrame</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.inventor_benchmark_plot">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">inventor_benchmark_plot</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">disambiguations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmarks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.inventor_benchmark_plot" title="Permalink to this definition">#</a></dt>
<dd><p>Bar plot of performance evaluation metrics on benchmark datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>disambiguations</strong> (<em>dict</em>) – dictionary of disambiguation results (disambiguation results are pandas Series with “mention-id” index and cluster assignment values).</p></li>
<li><p><strong>metrics</strong> (<em>dict</em><em>, </em><em>optional</em>) – dictionary of metrics (from the metrics submodule) to compute. Defaults to <cite>DEFAULT_METRICS</cite>.</p></li>
<li><p><strong>benchmarks</strong> (<em>dict</em><em>, </em><em>optional</em>) – benchmark datasets loading functions (from the benchmark submodule) to use. Defaults to <cite>DEFAULT_BENCHMARK</cite>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>plotly graph object</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.inventor_benchmark_table">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">inventor_benchmark_table</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">disambiguations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">benchmarks</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.inventor_benchmark_table" title="Permalink to this definition">#</a></dt>
<dd><p>Compute performance evaluation metrics on benchmark datasets.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>disambiguations</strong> (<em>dict</em>) – dictionary of disambiguation results (disambiguation results are pandas Series with “mention-id” index and cluster assignment values).</p></li>
<li><p><strong>metrics</strong> (<em>dict</em><em>, </em><em>optional</em>) – dictionary of metrics (from the metrics submodule) to compute. Defaults to <cite>DEFAULT_METRICS</cite>.</p></li>
<li><p><strong>benchmarks</strong> (<em>dict</em><em>, </em><em>optional</em>) – benchmark datasets loading functions to use from the benchmark submodule. Defaults to <cite>DEFAULT_BENCHMARK</cite>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.load_israeli_inventors_benchmark">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">load_israeli_inventors_benchmark</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.load_israeli_inventors_benchmark" title="Permalink to this definition">#</a></dt>
<dd><p>Israeli inventors benchmark dataset</p>
<p>This is adapted from Trajenberg and Shiff (2008). The data covers U.S. patents granted between 1963 and 1999 for Israeli inventors.</p>
<dl class="simple">
<dt>See:</dt><dd><p>Trajtenberg, M., &amp; Shiff, G. (2008). Identification and mobility of Israeli patenting inventors. Pinhas Sapir Center for Development.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pandas Series indexed by mention ID and with values corresponding to cluster assignment.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Series</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.load_lai_2011_inventors_benchmark">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">load_lai_2011_inventors_benchmark</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.load_lai_2011_inventors_benchmark" title="Permalink to this definition">#</a></dt>
<dd><p>Lai’s 2011 inventors benchmark dataset</p>
<p>This is adapted from the benchmark dataset reported in Lai et al. (2011) to evaluate their disambiguation of the  U.S. Patent Inventor Database (1975-2010).</p>
<p class="rubric">Notes</p>
<p>A number of patent IDs which could not be found were removed from Lai’s original dataset.
Inventor sequence numbers were assigned through automatic matching and manual review. There could be some errors.</p>
<dl class="simple">
<dt>See:</dt><dd><p>Li, G. C., Lai, R., D’Amour, A., Doolin, D. M., Sun, Y., Torvik, V. I., … &amp; Fleming, L. (2014). Disambiguation and co-authorship networks of the US patent inventor database (1975-2010). Research Policy, 43(6), 941-955.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pandas Series indexed by mention ID and with values corresponding to cluster assignment.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Series</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.load_patentsview_inventors_benchmark">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">load_patentsview_inventors_benchmark</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.load_patentsview_inventors_benchmark" title="Permalink to this definition">#</a></dt>
<dd><p>PatentsView hand-disambiguated inventors benchmark</p>
<p>This is the hand-disambiguation of a set of particularly ambiguous inventor names.</p>
<dl class="simple">
<dt>See:</dt><dd><p>Monath, N., Jones, C., &amp; Madhavan, S. Disambiguating Patent Inventors, Assignees, and their Locations in PatentsView. <a class="reference external" href="https://s3.amazonaws.com/data.patentsview.org/documents/PatentsView_Disambiguation_Methods_Documentation.pdf">https://s3.amazonaws.com/data.patentsview.org/documents/PatentsView_Disambiguation_Methods_Documentation.pdf</a></p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>pandas Series indexed by mention ID and with values corresponding to cluster assignment.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>Series</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="pv_evaluation.benchmark.style_cluster_inspection">
<span class="sig-prename descclassname"><span class="pre">pv_evaluation.benchmark.</span></span><span class="sig-name descname"><span class="pre">style_cluster_inspection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">table</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">by</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'prediction'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#pv_evaluation.benchmark.style_cluster_inspection" title="Permalink to this definition">#</a></dt>
<dd><p>Style table to highlight groups with alternating colors.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>table</strong> (<em>dataframe</em>) – DataFrame to style.</p></li>
<li><p><strong>by</strong> (<em>str</em><em>, </em><em>optional</em>) – column to color by. Defaults to “prediction”.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>


              </article>
              

              
              <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class='prev-next-area'>
  <a class='left-prev' id="prev-link" href="pv_evaluation.metrics.html" title="previous page">
      <i class="fas fa-angle-left"></i>
      <div class="prev-next-info">
          <p class="prev-next-subtitle">previous</p>
          <p class="prev-next-title">pv_evaluation.metrics</p>
      </div>
  </a>
  <a class='right-next' id="next-link" href="pv_evaluation.templates.html" title="next page">
  <div class="prev-next-info">
      <p class="prev-next-subtitle">next</p>
      <p class="prev-next-title">pv_evaluation.templates</p>
  </div>
  <i class="fas fa-angle-right"></i>
  </a>
</div>
              </footer>
              
          </div>
          
      </div>
    </div>

  
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=92025949c220c2e29695"></script>

<footer class="bd-footer"><div class="bd-footer__inner container">
  
  <div class="footer-item">
    <p class="copyright">
    &copy; Copyright 2022, PatentsView.org.<br>
</p>
  </div>
  
  <div class="footer-item">
    <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
  </div>
  
</div>
</footer>
  </body>
</html>