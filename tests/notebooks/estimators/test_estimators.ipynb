{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspectable execution tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from pv_evaluation.metrics import pairwise_precision_recall, cluster_precision_recall, cluster_recall, cluster_precision\n",
    "from pv_evaluation.estimators import pairwise_precision_estimator, pairwise_recall_estimator, cluster_precision_estimator, cluster_recall_estimator\n",
    "from pv_evaluation.benchmark import load_als_inventors_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = load_als_inventors_benchmark()\n",
    "\n",
    "# Create prediction membership vector as a noisy version of the reference\n",
    "prediction = reference.copy()\n",
    "for _ in range(10000):\n",
    "    i,j = np.random.randint(0, len(prediction), size=2)\n",
    "    prediction[i] = prediction[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True pairwise precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495857333565273 0.864769100993944\n"
     ]
    }
   ],
   "source": [
    "P, R = pairwise_precision_recall(prediction, reference)\n",
    "\n",
    "print(P, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True cluster precision and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649243999577063 0.9004875736439358\n"
     ]
    }
   ],
   "source": [
    "P_cluster, R_cluster = cluster_precision_recall(prediction, reference)\n",
    "\n",
    "print(P_cluster, R_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling clusters with probability proportional to their size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_clusters(reference, sample_size):\n",
    "    clusters = np.random.choice(reference.values, size=sample_size, replace=True)\n",
    "    return reference[reference.isin(clusters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for unbiasedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8286886262259623 0.8659868339137509\n",
      "0.8130723402604646 0.8665343519807581\n",
      "0.8432463003236158 0.8630406187342097\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "\n",
    "for params in [(\"record\", \"uniform\"), (\"cluster\", \"cluster_size\"), (\"cluster_block\", \"cluster_size\")]:\n",
    "    P_hat = np.zeros(k)\n",
    "    R_hat = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        sample = sample_clusters(reference, sample_size=200)\n",
    "        P_hat[i] = pairwise_precision_estimator(prediction, sample, sampling_type=params[0], weights=params[1])\n",
    "        R_hat[i] = pairwise_recall_estimator(prediction, sample, sampling_type=params[0], weights=params[1])\n",
    "\n",
    "    print(np.mean(P_hat), np.mean(R_hat))\n",
    "    assert np.abs(np.mean(P_hat) - P) < 0.05\n",
    "    assert np.abs(np.mean(R_hat) - R) < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417909754739342 0.8918661171483601\n"
     ]
    }
   ],
   "source": [
    "k = 100\n",
    "\n",
    "for params in [(\"cluster_block\", \"cluster_size\")]:\n",
    "    P_hat = np.zeros(k)\n",
    "    R_hat = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        sample = sample_clusters(reference, sample_size=200)\n",
    "        P_hat[i] = cluster_precision_estimator(prediction, sample, sampling_type=params[0], weights=params[1])\n",
    "        R_hat[i] = cluster_recall_estimator(prediction, sample, sampling_type=params[0], weights=params[1])\n",
    "\n",
    "    print(np.mean(P_hat), np.mean(R_hat))\n",
    "    assert np.abs(np.mean(P_hat) - P_cluster) < 0.05\n",
    "    assert np.abs(np.mean(R_hat) - R_cluster) < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling clusters uniformly at random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_clusters_uniformly(reference, sample_size):\n",
    "    clusters = np.random.choice(reference.unique(), size=sample_size, replace=True)\n",
    "    return reference[reference.isin(clusters)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for (near) unbiasedness. Note that bias of these ratio estimators would be high in small samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8228562617126128 0.8604932548282794\n",
      "0.836117074275537 0.8676234951792299\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "\n",
    "for params in [(\"cluster\", \"uniform\"), (\"cluster_block\", \"uniform\")]:\n",
    "    P_hat = np.zeros(k)\n",
    "    R_hat = np.zeros(k)\n",
    "\n",
    "    for i in range(k):\n",
    "        sample = sample_clusters_uniformly(reference, sample_size=400)\n",
    "        P_hat[i] = pairwise_precision_estimator(prediction, sample, sampling_type=params[0], weights=params[1])\n",
    "        R_hat[i] = pairwise_recall_estimator(prediction, sample, sampling_type=params[0], weights=params[1])\n",
    "\n",
    "    print(np.mean(P_hat), np.mean(R_hat))\n",
    "    assert np.abs(np.mean(P_hat) - P) < 0.05\n",
    "    assert np.abs(np.mean(R_hat) - R) < 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8528641966295608 0.905009585807827\n"
     ]
    }
   ],
   "source": [
    "k = 50\n",
    "\n",
    "for params in [(\"cluster_block\", \"uniform\")]:\n",
    "    P_hat = np.zeros(k)\n",
    "    R_hat = np.zeros(k)\n",
    "    for i in range(k):\n",
    "        sample = sample_clusters_uniformly(reference, sample_size=200)\n",
    "        P_hat[i] = cluster_precision_estimator(prediction, sample, sampling_type=params[0], weights=params[1])\n",
    "        R_hat[i] = cluster_recall_estimator(prediction, sample, sampling_type=params[0], weights=params[1]) \n",
    "    \n",
    "    print(np.mean(P_hat), np.mean(R_hat))\n",
    "    assert np.abs(np.mean(P_hat) - P_cluster) < 0.05\n",
    "    assert np.abs(np.mean(R_hat) - R_cluster) < 0.05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d366ceee791367589ff1ed6dc5fb57b1e5eb0d210a7a54b43020c52608fe54d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
